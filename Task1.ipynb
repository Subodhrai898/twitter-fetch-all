{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"----------------Python script to fetch all the tweets of the user from his/her timeline------------------------------------- \"\n",
    "\"----------------------------------------Author Subodh Rai-------------------------------------------------------------- \"\n",
    "\"----------------------------------Mail subodhrai898@gmail.com------------------------------------------------------------\"\n",
    "\"Use Tweepy module for twitter API\"\n",
    "\"Use Jsonline module to dump all tweets in .jsonl file\"\n",
    "\"Function used here get_tweets() for getting list \"\n",
    "\"Use Pandas Dataframes to show and store data in tabular form\"\n",
    "\"Please Read Comment to understand the code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block contain all imports and API Secret/Key \n",
    "#Required module for this project\n",
    "import tweepy,json                                               #tweepy use for twitter API and Json to handle json data\n",
    "import pandas as pd                                              #Pandas use for Dataframe and show information in tabular form\n",
    "import jsonlines                                                 #jsonlines module use to store json in .jsonl format that contain one line per json information\n",
    "from datetime import datetime                                    #this use to parse data\n",
    "access_token = \"2164637652-uGDxiZ8aPaThVexak2nkX8FLnoDEv2i4UOuj5yo\"                 #Access Token\n",
    "access_secret = \"vRGBewKNdGRkorFwIUjJJIpFfvXBBfy2EnI2OEZRfCwRR\"                     #Access Token Secret\n",
    "consumer_key = \"MrITPRcLi6Wp4YMnB0ygjpI4r\"                                          #Consumer Key used\n",
    "consumer_secret = \"5dDMlcoLuj4eYYuZ2vNE1Dqs1fyqKKEbDpfr410fFkKU9THKUO\"              #Consumer Key Secret\n",
    "\n",
    "#This all use in OAuth in twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function store list of tweets(data) in txt file here data is string of json fromat and file is name \n",
    "\n",
    "def store_txt(data,file):\n",
    "    with open(file,'w+') as f:\n",
    "        f.write(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function return list of tweets store in file in txt and return string tweet_str\n",
    "\n",
    "def load_txt(file):\n",
    "    tweets_str=\"\"\n",
    "    with open(file,'r') as f:\n",
    "        tweets_str = f.read()\n",
    "    return tweets_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"get_tweets is our main function which call Rest Api of twitter and api.user_timeline used to fetch all the tweets\"\n",
    "\"Here I used loop which extract tweet in bunch of 200 tweets at one time untill in next iteration we will not get any tweets\"\n",
    "\"I used extended mode to get all information of the tweet including images details and full text\"\n",
    "\"Please read the comment to understand more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is our main function that fetch all tweets of the user specify by username \n",
    "\n",
    "\n",
    "def get_tweets(username):\n",
    "    # Authorization to consumer key and consumer secret \n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "  \n",
    "        # Access to user's access key and access secret \n",
    "        auth.set_access_token(access_token, access_secret) \n",
    "  \n",
    "        # Calling api \n",
    "        api = tweepy.API(auth)\n",
    "        #List that store all tweets of the user\n",
    "        alltweets = []\n",
    "        #use api.user_timeline to fetch all tweets timeline\n",
    "        #we can also user Cursor for it but this somewhat controlable\n",
    "        #api.user_timeline take three argument and we use tweet_mode='extended' so that we get all information of image and media\n",
    "        #here we fetch first 200 tweets\n",
    "        new_tweets = api.user_timeline(screen_name=username, count=200,tweet_mode='extended')\n",
    "        #Extend our list\n",
    "        alltweets.extend(new_tweets)\n",
    "        #get ID of our last tweets so it use in max_ID\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        #this loop will help to extract all tweets from the user\n",
    "        while len(new_tweets) > 0:\n",
    "                    #Here we use same function api.user_timeline but use max_id so that next time we fetch tweets after that ID\n",
    "                    new_tweets = api.user_timeline(screen_name=username, count=200, max_id=oldest,tweet_mode='extended')\n",
    "                    alltweets.extend(new_tweets)\n",
    "                    oldest = alltweets[-1].id - 1\n",
    "        #return list of tweets\n",
    "        return alltweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will help to dump our alltweets list into jsonlines file \n",
    "\n",
    "def store_jsonl(alltweets,file):\n",
    "    writer = jsonlines.open(file, mode='w') #open jsonline file\n",
    "    for tweet in alltweets:\n",
    "            writer.write(tweet._json)      #dump one by one json of each tweet to file\n",
    "    writer.close()                         #Always close the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function I used to help me to visualize the content of alltweets in readable indented fashion store in a txt file.\n",
    "def store_in_txt(alltweets,file):       #alltweets is list of tweets\n",
    "        data1 = dict()                  #use dict to create only one json file where each tweet is fetched by number - 'tweet_no'\n",
    "        tweet_no = 1\n",
    "        \n",
    "       \n",
    "        for tweet in alltweets:                #Store All tweets in that dictionary with key to each tweet is tweet_no\n",
    "            data1[tweet_no] = tweet._json      #convert tweet to json\n",
    "            tweet_no+=1                        #update tweet_number\n",
    "       \n",
    "        json_str = json.dumps(data1,indent=4)  #dump it in string json_str with indentation equals to 4\n",
    "        store_txt(json_str,file)          \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Here I used Pandas Dataframe to show and store data in Tabular from\"\n",
    "\"Dataframes have columns Text , Like , Retweet_Count ,Number of Image\"\n",
    "\"Here I used Datetime as index and create a Time Series\"\n",
    "\"The benefit of Time Series Data is that we can easily analyse it\"\n",
    "\"Please read the comment to understand more\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function return dataframe that contain Time-series Data of Text , Like, Retweet_count and Number of Image\n",
    "\n",
    "\n",
    "def Create_DataFrame(tweets):        #take iterator of tweets here tweet is jsonline iterator\n",
    "    \n",
    "        \n",
    "        df = pd.DataFrame()          #create empty dataframe\n",
    "       \n",
    "        for result in tweets:        #iterate through each json line\n",
    "                                      \n",
    "            total_image = 0          #Use to count number of Image\n",
    "            try:\n",
    "                   total_image = len(result['entities']['media'])            #Image and video store in entitied->Media\n",
    "            except KeyError:                                             \n",
    "                   total_image = None                                        #Use try except to catch None image\n",
    "            \n",
    "            try:\n",
    "                    tota_image = len(result['extended_entities']['media'])   #This is important as earlier if we use simple mode we get only some image list\n",
    "                                                                             #The extend_entities->media will hold list of all images and work only in extended mode\n",
    "                    if(total_image==None):\n",
    "                        total_image=tota_image                               #We add total of image\n",
    "                    else:          \n",
    "                        total_image+=tota_image\n",
    "                \n",
    "            except KeyError:\n",
    "                   pass\n",
    "                \n",
    "            if(total_image!=None):                                            #We decrease count by one as it will include th profile picture also\n",
    "                total_image-=1\n",
    "                \n",
    "            \n",
    "            dm = {\"Text\":[result[\"full_text\"]],                               #Our one row of Data frame      \n",
    "              \"Date\":[pd.to_datetime(result[\"created_at\"][4:], format='%b %d %H:%M:%S +0000 %Y', utc=True)\n",
    "                      ], #This pd.to_dateTime will parse our date time so that we can use as index\n",
    "              \"Like\":[result[\"favorite_count\"]],                               #Number of Likes \n",
    "              \"Retweet_count\":[result[\"retweet_count\"]],                       #Number of Retweet\n",
    "            \"Number_image\":[total_image]}                                      #Total Images\n",
    "            #Append Row to dataframe df                                                 \n",
    "            df = df.append(pd.DataFrame(dm,columns=['Text', 'Date', 'Like','Retweet_count','Number_image']))\n",
    "        #Reset index and index data to Date and create a Time Series Data\n",
    "        df.set_index([\"Date\"], inplace = True) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function use to convert jsonl to dataframe\n",
    "def jsonl_to_dataframe(file):\n",
    "    reader = jsonlines.open(file,'r')\n",
    "    df = Create_DataFrame(reader)               #Call Create_DataFrame\n",
    "    reader.close()\n",
    "    return df                                   #Return Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time to Compile my whole Work\n",
    "filejson = \"data.jsonl\"                                 #File name of our .jsonl\n",
    "filetxt = \"data.txt\"                                    #File name of our .txt\n",
    "username=\"midasIIITD\"                                   #User name of the screen/handle\n",
    "tweets = get_tweets(username)                           #Start to get all tweets list\n",
    "store_jsonl(tweets,filejson)                            #dumo in jsonline file\n",
    "store_in_txt(tweets,filetxt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jsonl_to_dataframe(filejson)                       #Convert Jsonline to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 333 entries, 2019-04-07 06:55:19+00:00 to 2018-07-23 12:53:15+00:00\n",
      "Data columns (total 4 columns):\n",
      "Text             333 non-null object\n",
      "Like             333 non-null int64\n",
      "Retweet_count    333 non-null int64\n",
      "No_image         47 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 13.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()                                               #Information about our DataFram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Like</th>\n",
       "      <th>Retweet_count</th>\n",
       "      <th>Number_image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-07 06:55:19+00:00</th>\n",
       "      <td>Other queries: \"none of the Tweeter Apis give ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-07 06:53:38+00:00</th>\n",
       "      <td>Other queries: \"do we have to make two differe...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-07 05:32:27+00:00</th>\n",
       "      <td>Other queries: \"If using Twitter api, it does ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-07 05:29:40+00:00</th>\n",
       "      <td>Response to some queries asked by students on ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-06 17:11:29+00:00</th>\n",
       "      <td>RT @kdnuggets: Top 8 #Free Must-Read #Books on...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-06 16:43:27+00:00</th>\n",
       "      <td>@nupur_baghel @PennDATS Congratulation @nupur_...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 16:08:37+00:00</th>\n",
       "      <td>We have emailed the task details to all candid...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 04:05:11+00:00</th>\n",
       "      <td>RT @rfpvjr: Our NAACL paper on polarization in...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05 04:04:43+00:00</th>\n",
       "      <td>RT @kdnuggets: Effective Transfer Learning For...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 18:31:53+00:00</th>\n",
       "      <td>RT @stanfordnlp: What’s new in @Stanford CS224...</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 17:04:32+00:00</th>\n",
       "      <td>RT @DeepMindAI: Today we're releasing a large-...</td>\n",
       "      <td>0</td>\n",
       "      <td>848</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 09:03:40+00:00</th>\n",
       "      <td>RT @ylecun: Congratulations Jitendra Malik !\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03 07:46:02+00:00</th>\n",
       "      <td>RT @IIITDelhi: Another chance to take admissio...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-02 04:20:13+00:00</th>\n",
       "      <td>Dear @midasIIITD internship candidates who hav...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-02 02:44:54+00:00</th>\n",
       "      <td>Looking forward to your paper submission to @I...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-02 02:35:44+00:00</th>\n",
       "      <td>RT @ngrams: Reproducibility in multimedia rese...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01 06:53:08+00:00</th>\n",
       "      <td>Online application for https://t.co/DJFDrQsHZP...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31 10:21:24+00:00</th>\n",
       "      <td>RT @ACMMM19: A final reminder of the Reproduci...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 19:43:24+00:00</th>\n",
       "      <td>RT @isarth23: Thanks for the support and help ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 17:16:40+00:00</th>\n",
       "      <td>Since SemEval-2019 will be held June 6-7, 2019...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 17:04:30+00:00</th>\n",
       "      <td>+@aggarwal_kartik.\\nCongrats! Wish you many mo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 17:03:29+00:00</th>\n",
       "      <td>RT @aggarwal_kartik: Our work (@midasIIITD ) a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 17:02:24+00:00</th>\n",
       "      <td>Congratulations! @midasIIITD team, @isarth23 @...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 05:35:22+00:00</th>\n",
       "      <td>@EEMLcommunity @radamihalcea too many deadline...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28 16:55:01+00:00</th>\n",
       "      <td>RT @stanfordnlp: CS224N Natural Language Proce...</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28 16:54:37+00:00</th>\n",
       "      <td>RT @ylecun: Learn PyTorch by running on Google...</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27 16:09:09+00:00</th>\n",
       "      <td>Dr. Vineeth N Balasubramanian will present a T...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27 11:53:40+00:00</th>\n",
       "      <td>RT @ylecun: I am extremely honored to be the r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1545</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-26 18:12:27+00:00</th>\n",
       "      <td>Thanks to all shortlisted candidates for submi...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-26 05:54:49+00:00</th>\n",
       "      <td>@IEEEBigMM19 @ACMMM19 and 6 days left for work...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-09 05:59:57+00:00</th>\n",
       "      <td>RT @TensorFlow: TensorFlow 1.10.0 has been rel...</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 11:30:56+00:00</th>\n",
       "      <td>@midasIIITD is looking for motivated IIITD MTe...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 05:53:48+00:00</th>\n",
       "      <td>@IIITDelhi @ponguru @RatnRajiv The results of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08 05:45:58+00:00</th>\n",
       "      <td>RT @IIITDelhi: @midasIIITD has secured rank 1 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-07 07:16:33+00:00</th>\n",
       "      <td>RT @kdnuggets: Comparison of Top 6 Python NLP ...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-07 02:05:12+00:00</th>\n",
       "      <td>Check more details of the 20th IEEE Internatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-07 01:58:49+00:00</th>\n",
       "      <td>MR2AMC@ISM 2018 will be organized by @RatnRaji...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-07 01:50:33+00:00</th>\n",
       "      <td>Our workshop proposal named, \"MR2AMC: Multimod...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-06 17:48:23+00:00</th>\n",
       "      <td>@NUSComputing Congratulations Abdelhak and Pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-06 17:46:59+00:00</th>\n",
       "      <td>RT @goodfellow_ian: One of the most anticipate...</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-06 06:06:47+00:00</th>\n",
       "      <td>@the_dhumketu Great to have you in @midasIIITD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03 05:56:33+00:00</th>\n",
       "      <td>Congratulation @soujanyaporia for being appoin...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 11:47:15+00:00</th>\n",
       "      <td>@IIITDelhi @the_dhumketu Thanks team @midasIII...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 11:20:07+00:00</th>\n",
       "      <td>RT @IIITDelhi: Congratulations @midasIIITD int...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 05:06:47+00:00</th>\n",
       "      <td>RT @learning_pt: Profile of the 5 Indian under...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 12:11:52+00:00</th>\n",
       "      <td>Have a look at the list of accepted papers in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 02:06:26+00:00</th>\n",
       "      <td>RT @goodfellow_ian: https://t.co/hYiWI7ntyk Te...</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 07:30:51+00:00</th>\n",
       "      <td>RT @IIITDelhi: Congratulations Dr. @RatnRajiv ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-28 11:07:11+00:00</th>\n",
       "      <td>RT @ylecun: Jitendra Malik, who directs FAIR-M...</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-28 06:14:09+00:00</th>\n",
       "      <td>RT @kdnuggets: .@Bloomberg launches free cours...</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-28 06:13:48+00:00</th>\n",
       "      <td>RT @TechAtBloomberg: Missed #PyLondinium18? Wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-28 04:08:21+00:00</th>\n",
       "      <td>RT @IIITDelhi: We are delighted to announce th...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-27 06:46:44+00:00</th>\n",
       "      <td>Get ready for the annual technical fest of @II...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-27 04:07:31+00:00</th>\n",
       "      <td>Congratulations Dr. @RatnRajiv and team @midas...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-25 05:14:35+00:00</th>\n",
       "      <td>Congratulations MIDAS @midasIIITD intern Prakh...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-24 10:33:23+00:00</th>\n",
       "      <td>MIDAS@IIITD foundation. https://t.co/LKuzyBHzjm</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-24 10:12:34+00:00</th>\n",
       "      <td>It feels great to be the part of @IIITDelhi. h...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-24 09:46:26+00:00</th>\n",
       "      <td>Thank you, @toonzratn for designing the logo o...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-23 16:25:05+00:00</th>\n",
       "      <td>We are on Facebook too. Like our page to get o...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-23 12:53:15+00:00</th>\n",
       "      <td>MIDAS is a group of researchers at IIIT-Delhi ...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Text  \\\n",
       "Date                                                                           \n",
       "2019-04-07 06:55:19+00:00  Other queries: \"none of the Tweeter Apis give ...   \n",
       "2019-04-07 06:53:38+00:00  Other queries: \"do we have to make two differe...   \n",
       "2019-04-07 05:32:27+00:00  Other queries: \"If using Twitter api, it does ...   \n",
       "2019-04-07 05:29:40+00:00  Response to some queries asked by students on ...   \n",
       "2019-04-06 17:11:29+00:00  RT @kdnuggets: Top 8 #Free Must-Read #Books on...   \n",
       "2019-04-06 16:43:27+00:00  @nupur_baghel @PennDATS Congratulation @nupur_...   \n",
       "2019-04-05 16:08:37+00:00  We have emailed the task details to all candid...   \n",
       "2019-04-05 04:05:11+00:00  RT @rfpvjr: Our NAACL paper on polarization in...   \n",
       "2019-04-05 04:04:43+00:00  RT @kdnuggets: Effective Transfer Learning For...   \n",
       "2019-04-03 18:31:53+00:00  RT @stanfordnlp: What’s new in @Stanford CS224...   \n",
       "2019-04-03 17:04:32+00:00  RT @DeepMindAI: Today we're releasing a large-...   \n",
       "2019-04-03 09:03:40+00:00  RT @ylecun: Congratulations Jitendra Malik !\\n...   \n",
       "2019-04-03 07:46:02+00:00  RT @IIITDelhi: Another chance to take admissio...   \n",
       "2019-04-02 04:20:13+00:00  Dear @midasIIITD internship candidates who hav...   \n",
       "2019-04-02 02:44:54+00:00  Looking forward to your paper submission to @I...   \n",
       "2019-04-02 02:35:44+00:00  RT @ngrams: Reproducibility in multimedia rese...   \n",
       "2019-04-01 06:53:08+00:00  Online application for https://t.co/DJFDrQsHZP...   \n",
       "2019-03-31 10:21:24+00:00  RT @ACMMM19: A final reminder of the Reproduci...   \n",
       "2019-03-29 19:43:24+00:00  RT @isarth23: Thanks for the support and help ...   \n",
       "2019-03-29 17:16:40+00:00  Since SemEval-2019 will be held June 6-7, 2019...   \n",
       "2019-03-29 17:04:30+00:00  +@aggarwal_kartik.\\nCongrats! Wish you many mo...   \n",
       "2019-03-29 17:03:29+00:00  RT @aggarwal_kartik: Our work (@midasIIITD ) a...   \n",
       "2019-03-29 17:02:24+00:00  Congratulations! @midasIIITD team, @isarth23 @...   \n",
       "2019-03-29 05:35:22+00:00  @EEMLcommunity @radamihalcea too many deadline...   \n",
       "2019-03-28 16:55:01+00:00  RT @stanfordnlp: CS224N Natural Language Proce...   \n",
       "2019-03-28 16:54:37+00:00  RT @ylecun: Learn PyTorch by running on Google...   \n",
       "2019-03-27 16:09:09+00:00  Dr. Vineeth N Balasubramanian will present a T...   \n",
       "2019-03-27 11:53:40+00:00  RT @ylecun: I am extremely honored to be the r...   \n",
       "2019-03-26 18:12:27+00:00  Thanks to all shortlisted candidates for submi...   \n",
       "2019-03-26 05:54:49+00:00  @IEEEBigMM19 @ACMMM19 and 6 days left for work...   \n",
       "...                                                                      ...   \n",
       "2018-08-09 05:59:57+00:00  RT @TensorFlow: TensorFlow 1.10.0 has been rel...   \n",
       "2018-08-08 11:30:56+00:00  @midasIIITD is looking for motivated IIITD MTe...   \n",
       "2018-08-08 05:53:48+00:00  @IIITDelhi @ponguru @RatnRajiv The results of ...   \n",
       "2018-08-08 05:45:58+00:00  RT @IIITDelhi: @midasIIITD has secured rank 1 ...   \n",
       "2018-08-07 07:16:33+00:00  RT @kdnuggets: Comparison of Top 6 Python NLP ...   \n",
       "2018-08-07 02:05:12+00:00  Check more details of the 20th IEEE Internatio...   \n",
       "2018-08-07 01:58:49+00:00  MR2AMC@ISM 2018 will be organized by @RatnRaji...   \n",
       "2018-08-07 01:50:33+00:00  Our workshop proposal named, \"MR2AMC: Multimod...   \n",
       "2018-08-06 17:48:23+00:00  @NUSComputing Congratulations Abdelhak and Pro...   \n",
       "2018-08-06 17:46:59+00:00  RT @goodfellow_ian: One of the most anticipate...   \n",
       "2018-08-06 06:06:47+00:00     @the_dhumketu Great to have you in @midasIIITD   \n",
       "2018-08-03 05:56:33+00:00  Congratulation @soujanyaporia for being appoin...   \n",
       "2018-08-01 11:47:15+00:00  @IIITDelhi @the_dhumketu Thanks team @midasIII...   \n",
       "2018-08-01 11:20:07+00:00  RT @IIITDelhi: Congratulations @midasIIITD int...   \n",
       "2018-08-01 05:06:47+00:00  RT @learning_pt: Profile of the 5 Indian under...   \n",
       "2018-07-31 12:11:52+00:00  Have a look at the list of accepted papers in ...   \n",
       "2018-07-31 02:06:26+00:00  RT @goodfellow_ian: https://t.co/hYiWI7ntyk Te...   \n",
       "2018-07-30 07:30:51+00:00  RT @IIITDelhi: Congratulations Dr. @RatnRajiv ...   \n",
       "2018-07-28 11:07:11+00:00  RT @ylecun: Jitendra Malik, who directs FAIR-M...   \n",
       "2018-07-28 06:14:09+00:00  RT @kdnuggets: .@Bloomberg launches free cours...   \n",
       "2018-07-28 06:13:48+00:00  RT @TechAtBloomberg: Missed #PyLondinium18? Wa...   \n",
       "2018-07-28 04:08:21+00:00  RT @IIITDelhi: We are delighted to announce th...   \n",
       "2018-07-27 06:46:44+00:00  Get ready for the annual technical fest of @II...   \n",
       "2018-07-27 04:07:31+00:00  Congratulations Dr. @RatnRajiv and team @midas...   \n",
       "2018-07-25 05:14:35+00:00  Congratulations MIDAS @midasIIITD intern Prakh...   \n",
       "2018-07-24 10:33:23+00:00    MIDAS@IIITD foundation. https://t.co/LKuzyBHzjm   \n",
       "2018-07-24 10:12:34+00:00  It feels great to be the part of @IIITDelhi. h...   \n",
       "2018-07-24 09:46:26+00:00  Thank you, @toonzratn for designing the logo o...   \n",
       "2018-07-23 16:25:05+00:00  We are on Facebook too. Like our page to get o...   \n",
       "2018-07-23 12:53:15+00:00  MIDAS is a group of researchers at IIIT-Delhi ...   \n",
       "\n",
       "                           Like  Retweet_count Number_image  \n",
       "Date                                                         \n",
       "2019-04-07 06:55:19+00:00     3              2         None  \n",
       "2019-04-07 06:53:38+00:00     3              1         None  \n",
       "2019-04-07 05:32:27+00:00     4              1         None  \n",
       "2019-04-07 05:29:40+00:00     6              1         None  \n",
       "2019-04-06 17:11:29+00:00     0              2         None  \n",
       "2019-04-06 16:43:27+00:00    14              3            1  \n",
       "2019-04-05 16:08:37+00:00    10              1         None  \n",
       "2019-04-05 04:05:11+00:00     0             16         None  \n",
       "2019-04-05 04:04:43+00:00     0             10            1  \n",
       "2019-04-03 18:31:53+00:00     0             58         None  \n",
       "2019-04-03 17:04:32+00:00     0            848         None  \n",
       "2019-04-03 09:03:40+00:00     0             16         None  \n",
       "2019-04-03 07:46:02+00:00     0              4         None  \n",
       "2019-04-02 04:20:13+00:00     8              1         None  \n",
       "2019-04-02 02:44:54+00:00     5              1         None  \n",
       "2019-04-02 02:35:44+00:00     0              7         None  \n",
       "2019-04-01 06:53:08+00:00     7              2         None  \n",
       "2019-03-31 10:21:24+00:00     0             10         None  \n",
       "2019-03-29 19:43:24+00:00     0              2         None  \n",
       "2019-03-29 17:16:40+00:00     9              1         None  \n",
       "2019-03-29 17:04:30+00:00     2              0         None  \n",
       "2019-03-29 17:03:29+00:00     0              1         None  \n",
       "2019-03-29 17:02:24+00:00     9              1         None  \n",
       "2019-03-29 05:35:22+00:00     0              0         None  \n",
       "2019-03-28 16:55:01+00:00     0            715         None  \n",
       "2019-03-28 16:54:37+00:00     0            157         None  \n",
       "2019-03-27 16:09:09+00:00     4              1            1  \n",
       "2019-03-27 11:53:40+00:00     0           1545         None  \n",
       "2019-03-26 18:12:27+00:00     5              1         None  \n",
       "2019-03-26 05:54:49+00:00     2              0         None  \n",
       "...                         ...            ...          ...  \n",
       "2018-08-09 05:59:57+00:00     0            265         None  \n",
       "2018-08-08 11:30:56+00:00     2              1         None  \n",
       "2018-08-08 05:53:48+00:00     3              1            1  \n",
       "2018-08-08 05:45:58+00:00     0              1         None  \n",
       "2018-08-07 07:16:33+00:00     0             40            1  \n",
       "2018-08-07 02:05:12+00:00     1              1         None  \n",
       "2018-08-07 01:58:49+00:00     1              1         None  \n",
       "2018-08-07 01:50:33+00:00     1              1         None  \n",
       "2018-08-06 17:48:23+00:00     0              0         None  \n",
       "2018-08-06 17:46:59+00:00     0            103            1  \n",
       "2018-08-06 06:06:47+00:00     0              0         None  \n",
       "2018-08-03 05:56:33+00:00     6              1         None  \n",
       "2018-08-01 11:47:15+00:00     5              1            1  \n",
       "2018-08-01 11:20:07+00:00     0              4         None  \n",
       "2018-08-01 05:06:47+00:00     0              4         None  \n",
       "2018-07-31 12:11:52+00:00     1              0         None  \n",
       "2018-07-31 02:06:26+00:00     0            264         None  \n",
       "2018-07-30 07:30:51+00:00     0              2         None  \n",
       "2018-07-28 11:07:11+00:00     0             57         None  \n",
       "2018-07-28 06:14:09+00:00     0            105         None  \n",
       "2018-07-28 06:13:48+00:00     0              7         None  \n",
       "2018-07-28 04:08:21+00:00     0              6         None  \n",
       "2018-07-27 06:46:44+00:00     3              2         None  \n",
       "2018-07-27 04:07:31+00:00     8              2         None  \n",
       "2018-07-25 05:14:35+00:00     5              1         None  \n",
       "2018-07-24 10:33:23+00:00     2              1         None  \n",
       "2018-07-24 10:12:34+00:00     2              1         None  \n",
       "2018-07-24 09:46:26+00:00     4              1            1  \n",
       "2018-07-23 16:25:05+00:00     3              1         None  \n",
       "2018-07-23 12:53:15+00:00     7              4         None  \n",
       "\n",
       "[333 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
